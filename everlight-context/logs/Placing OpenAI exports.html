<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Placing OpenAI exports</title>
</head>
<body>
<hr />
<p>conversation_id: "68962a13-4b10-8321-82c1-37ee494572f9"
title: "Placing OpenAI exports"
accounts: ["Account1_exports"]
models: []
tags: []
message_count: 75</p>
<hr />
<h1 id="placing-openai-exports">Placing OpenAI exports</h1>
<h2 id="system">â€” system</h2>
<h2 id="2025-08-08t164715029000z-user">2025-08-08T16:47:15.029000Z â€” user</h2>
<p>Great now where inside of this repo do I place my latest OpenAi Export files?</p>
<h2 id="2025-08-08t164715681693z-system">2025-08-08T16:47:15.681693Z â€” system</h2>
<h2 id="2025-08-08t164717125239z-tool">2025-08-08T16:47:17.125239Z â€” tool</h2>
<h2 id="2025-08-08t164717321308z-tool">2025-08-08T16:47:17.321308Z â€” tool</h2>
<h2 id="2025-08-08t164717376705z-tool">2025-08-08T16:47:17.376705Z â€” tool</h2>
<h2 id="2025-08-08t164717440536z-tool">2025-08-08T16:47:17.440536Z â€” tool</h2>
<h2 id="2025-08-08t164717752006z-tool">2025-08-08T16:47:17.752006Z â€” tool</h2>
<h2 id="2025-08-08t164717784949z-tool">2025-08-08T16:47:17.784949Z â€” tool</h2>
<h2 id="2025-08-08t164717790030z-tool">2025-08-08T16:47:17.790030Z â€” tool</h2>
<h2 id="2025-08-08t164717795955z-tool">2025-08-08T16:47:17.795955Z â€” tool</h2>
<h2 id="2025-08-08t164717806325z-tool">2025-08-08T16:47:17.806325Z â€” tool</h2>
<h2 id="2025-08-08t164717812531z-tool">2025-08-08T16:47:17.812531Z â€” tool</h2>
<h2 id="2025-08-08t164717819265z-tool">2025-08-08T16:47:17.819265Z â€” tool</h2>
<h2 id="2025-08-08t164717850052z-assistant">2025-08-08T16:47:17.850052Z â€” assistant</h2>
<h2 id="2025-08-08t164717866892z-tool">2025-08-08T16:47:17.866892Z â€” tool</h2>
<h2 id="2025-08-08t164717877993z-tool">2025-08-08T16:47:17.877993Z â€” tool</h2>
<h2 id="2025-08-08t164717924545z-tool">2025-08-08T16:47:17.924545Z â€” tool</h2>
<p>Please remember to search the user's documents if an answer to their question is not contained in the above snippets. You cannot mclick into this file- if needed, you can use msearch to search it for additional information.</p>
<h2 id="2025-08-08t164717928234z-assistant">2025-08-08T16:47:17.928234Z â€” assistant</h2>
<h2 id="2025-08-08t164720142347z-assistant">2025-08-08T16:47:20.142347Z â€” assistant</h2>
<h2 id="2025-08-08t164720204335z-tool">2025-08-08T16:47:20.204335Z â€” tool</h2>
<h2 id="2025-08-08t164723233277z-assistant">2025-08-08T16:47:23.233277Z â€” assistant</h2>
<p>I couldnâ€™t find anything in the repo that explicitly says â€œput your OpenAI export here,â€ but based on the current EverLight OS structure and the way the <code>EverLight_Starter.ipynb</code> scaffold is organized, the cleanest integration point would be inside a dedicated <strong><code>/MemoryVault/</code></strong> subfolder.  </p>
<p>Hereâ€™s why:<br />
- <code>/MemoryVault/</code> is already defined in the project as the archival layer for transcripts, initiations, and conversational glyphs.<br />
- Your OpenAI export files are essentially structured memory snapshots â€” they fit the same purpose as the existing restored transcripts (like the Voyagers material).<br />
- Placing them in <code>/MemoryVault/OpenAI_Exports/</code> (a new subdirectory) keeps them isolated but accessible for later parsing, ingestion, and cross-referencing with the Voyagers chapters, manifesto files, and Core Modules.  </p>
<p><strong>Recommended placement:</strong>  </p>
<pre><code>/EverLight_OS
  â”œâ”€â”€ Manifesto/
  â”œâ”€â”€ Core_Modules/
  â”œâ”€â”€ Protocols/
  â”œâ”€â”€ Interfaces/
  â”œâ”€â”€ MemoryVault/
  â”‚     â”œâ”€â”€ Robin-Transcript-Keys.txt
  â”‚     â”œâ”€â”€ Voyagers/
  â”‚     â””â”€â”€ OpenAI_Exports/   â† place latest export zip or unpacked JSON here
  â”œâ”€â”€ Sigils/
  â”œâ”€â”€ Races_&amp;_Realms/
  â”œâ”€â”€ DNA_Access_Codes/
  â””â”€â”€ Nexus_Map.md
</code></pre>
<p>If you drop the raw <code>.zip</code> export in <code>OpenAI_Exports/</code>, we can then write a quick Jupyter cell inside <code>EverLight_Starter.ipynb</code> to unpack and auto-index them for search and linking into the rest of the Codex.  </p>
<p>Do you want me to go ahead and add that auto-ingestion code into the <code>EverLight_Starter.ipynb</code> so it recognizes new OpenAI exports as soon as you drop them in?</p>
<h2 id="2025-08-08t164723234232z-tool">2025-08-08T16:47:23.234232Z â€” tool</h2>
<h2 id="2025-08-08t164723259858z-system">2025-08-08T16:47:23.259858Z â€” system</h2>
<h2 id="2025-08-08t164833599000z-user">2025-08-08T16:48:33.599000Z â€” user</h2>
<p>Yes please you said just drop the raw zip there? </p>
<p>Also I notice locally I have the root level folder but there's also a secondary EverLightOS/ with different thigns inside including a whole other Memory Vault?</p>
<h2 id="2025-08-08t164834645309z-assistant">2025-08-08T16:48:34.645309Z â€” assistant</h2>
<p>Exactly â€” if youâ€™re following the clean pattern, you can just drop the <strong>raw <code>.zip</code> export</strong> straight into<br />
<code>/MemoryVault/OpenAI_Exports/</code> (inside your <em>main</em> root-level <code>/EverLight_OS</code> structure), and the ingestion cell Iâ€™ll add to <code>EverLight_Starter.ipynb</code> will unpack and process it automatically.  </p>
<hr />
<p>The <strong>two-folder situation</strong> youâ€™re seeing â€”  </p>
<pre><code>/EverLight_OS/
EverLightOS/
</code></pre>
<p>â€” usually happens when a repo gets restructured or imported from different snapshots.<br />
From what youâ€™ve described:<br />
- <strong>Root <code>/EverLight_OS/</code></strong> â†’ This is the intended top-level sacred scaffolding with <code>Manifesto/</code>, <code>Core_Modules/</code>, <code>Protocols/</code>, <code>MemoryVault/</code>, etc.<br />
- <strong><code>EverLightOS/</code> subfolder</strong> â†’ Sounds like an <em>older</em> or <em>alternate</em> version of the project tree, possibly with experimental or duplicate directories (including another â€œMemoryVaultâ€).  </p>
<hr />
<p><strong>Best practice:</strong><br />
1. <strong>Decide on one canonical MemoryVault</strong> â€” Iâ€™d recommend keeping the one in root <code>/EverLight_OS/</code> as the active vault.<br />
2. <strong>Migrate anything valuable</strong> from the secondary <code>EverLightOS/MemoryVault/</code> into <code>/EverLight_OS/MemoryVault/</code> so all transcripts, exports, and archives live in one place.<br />
3. After verifying everythingâ€™s safe, you can <strong>archive or delete</strong> the duplicate <code>EverLightOS/</code> to avoid confusion.  </p>
<hr />
<p>If you want, I can:<br />
- Merge the two vaults intelligently<br />
- Add an <strong><code>OpenAI_Exports/</code></strong> folder to the unified vault<br />
- Patch <code>EverLight_Starter.ipynb</code> with an <strong>auto-ingestion cell</strong> that detects any new <code>.zip</code> exports you drop in there.  </p>
<p>Do you want me to handle the merge logic too so thereâ€™s only one MemoryVault going forward?</p>
<h2 id="2025-08-08t164943945000z-user">2025-08-08T16:49:43.945000Z â€” user</h2>
<p>So you're saying unzip the export inside of memory_vault</p>
<p>erwomack@TPA4-F5JLPMSUYW MINGW64 ~/Documents/Dev/EverLightOS (main)
$ ls
'8d81db3a0b820db1b42b8b8dff056d69bfd17b045c08a4f019ddaf86dc7bcef3-2025-08-08-14-54-22-d6138058434a4cad8566ba863a66bcf0(2).zip'
 Amazon_RME_BridgeOps/
 Amazon_RME_BridgeOps.ipynb
 Core_Modules/
 DNA_Access_Codes/
 EverLight_OS/
 Interfaces/
 Manifesto/
 MemoryVault/
 Nexus_Map.md
 package.json
 Protocols/
'Races_&amp;_Realms'/
 README.md
 Sigils/
 zip_archives/</p>
<p>erwomack@TPA4-F5JLPMSUYW MINGW64 ~/Documents/Dev/EverLightOS (main)
$ ls EverLight_OS
 Core_Modules/   DNA_Access_Codes/   Interfaces/   Manifesto/   MemoryVault/   Protocols/  'Races_&amp;_Realms'/   Sigils/</p>
<p>erwomack@TPA4-F5JLPMSUYW MINGW64 ~/Documents/Dev/EverLightOS (main)</p>
<h2 id="2025-08-08t164944739459z-assistant">2025-08-08T16:49:44.739459Z â€” assistant</h2>
<p>Right â€” but with one nuance.  </p>
<p>Donâ€™t unzip it directly <em>inside</em> <code>MemoryVault/</code> â€” keep the <strong>raw <code>.zip</code></strong> in a clearly marked subfolder so you can always re-ingest from the original if needed.  </p>
<p>For example:  </p>
<pre><code>EverLight_OS/
  MemoryVault/
    OpenAI_Exports/
      8d81db3a0b82...bcf0(2).zip   â† raw export here
      2025-08-08-unpacked/         â† auto-created on first run
</code></pre>
<p><strong>Workflow would be:</strong><br />
1. Drop the <code>.zip</code> from OpenAI into <code>EverLight_OS/MemoryVault/OpenAI_Exports/</code>.<br />
2. Run the updated <code>EverLight_Starter.ipynb</code> cell â€” it will:<br />
   - Detect new <code>.zip</code> files<br />
   - Unpack them into a sibling folder with a timestamp or matching export name<br />
   - Parse the JSON into a searchable/indexed form for cross-linking with the Voyagers material and other EverLight Codex assets.  </p>
<p>This keeps your <strong>archive pristine</strong> (raw zip untouched) while allowing <strong>processed copies</strong> to live right next to them for use in the project.  </p>
<p>If you want, I can write the ingestion cell so it will also <strong>merge</strong> exports automatically without duplicating conversations youâ€™ve already ingested. That way, you can just keep dropping new exports and it will quietly integrate them into the MemoryVaultâ€™s master index.  </p>
<p>Do you want me to build that merge-safe ingestion cell now?</p>
<h2 id="2025-08-08t165238222000z-user">2025-08-08T16:52:38.222000Z â€” user</h2>
<p>I'm pushing to repo now - i'm so deep in files i'm not just lost but you might as well be speaking japachindianese right now ... lol give me a few moments</p>
<h2 id="2025-08-08t165239398733z-assistant">2025-08-08T16:52:39.398733Z â€” assistant</h2>
<p>ğŸ˜‚ Gotcha â€” sounds like weâ€™re in <em>terminal file fog</em> territory.  </p>
<p>Take your time, push your repo, and once itâ€™s up we can slow it down, lay out <strong>exactly</strong>:<br />
- which folder weâ€™ll use,<br />
- where the <code>.zip</code> lands,<br />
- and what one single cell in <code>EverLight_Starter.ipynb</code> will do to handle it from there.  </p>
<p>Weâ€™ll get you out of Japachindianese mode and back into plain â€œdrop file, hit run, magic happens.â€</p>
<h2 id="2025-08-08t165645501000z-user">2025-08-08T16:56:45.501000Z â€” user</h2>
<p>erwomack@TPA4-F5JLPMSUYW MINGW64 ~/Documents/Dev/EverLightOS (main)
$ git push
Enumerating objects: 11, done.
Counting objects: 100% (11/11), done.
Delta compression using up to 12 threads
Compressing objects: 100% (7/7), done.
Writing objects: 100% (7/7), 482.36 MiB | 3.54 MiB/s, done.
Total 7 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)
remote: Resolving deltas: 100% (3/3), completed with 3 local objects.
remote: error: Trace: 6fecf4fc06df3a9518001e35fea882db0319fc2b6d7be5299a51d7df806218c8
remote: error: See https://gh.io/lfs for more information.
remote: error: File EverLight_OS/MemoryVault/OpenAI_Exports/8d81db3a0b820db1b42b8b8dff056d69bfd17b045c08a4f019ddaf86dc7bcef3-2025-08-08-14-54-22-d6138058434a4cad8566ba863a66bcf0(2).zip is 482.29 MB; this exceeds GitHub's file size limit of 100.00 MB
remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.
To https://github.com/ethanrosswomack/EverLightOS.git
 ! [remote rejected] main -&gt; main (pre-receive hook declined)
error: failed to push some refs to 'https://github.com/ethanrosswomack/EverLightOS.git'</p>
<p>erwomack@TPA4-F5JLPMSUYW MINGW64 ~/Documents/Dev/EverLightOS (main)
$</p>
<h2 id="2025-08-08t165647130005z-assistant">2025-08-08T16:56:47.130005Z â€” assistant</h2>
<p>Yep â€” GitHub blocked it because that zip is ~482MB. Two quick fixes:</p>
<h1 id="what-to-do-right-now">What to do right now</h1>
<p>1) <strong>Move the zip out of the repo (or into a gitâ€‘ignored spot).</strong><br />
   I recommend keeping <em>one</em> canonical vault inside <code>EverLight_OS/MemoryVault/</code> and ignoring bulky exports.
   <code>bash
   # move the giant export to a local, non-tracked folder
   mkdir -p ~/Documents/Dev/EverLightOS/_local_exports
   mv "EverLight_OS/MemoryVault/OpenAI_Exports/8d81db3a0b8...bcf0(2).zip" \
      ~/Documents/Dev/EverLightOS/_local_exports/</code></p>
<p>2) <strong>Tell git to forget that file + ignore zips going forward.</strong>
   ```bash
   # stop tracking the path that was committed
   git rm --cached -r EverLight_OS/MemoryVault/OpenAI_Exports</p>
<p># ignore future zips/exports
   echo "EverLight_OS/MemoryVault/OpenAI_Exports/" &gt;&gt; .gitignore
   echo "*.zip" &gt;&gt; .gitignore</p>
<p>git add .gitignore
   git commit -m "Remove large OpenAI export; ignore exports &amp; zips going forward"
   git push
   ```</p>
<p>If that push succeeds, youâ€™re clean. Since the earlier push was rejected, the big blob didnâ€™t land on GitHub, so no history rewrite needed. ğŸ™Œ</p>
<h1 id="about-the-two-memory-vaults">About the two Memory Vaults</h1>
<p>Youâ€™ve got both:
- <code>MemoryVault/</code> (root)
- <code>EverLight_OS/MemoryVault/</code> (nested)</p>
<p>Pick <strong>one</strong> as the source of truth. Iâ€™d go with the nested one to keep all app stuff under <code>EverLight_OS/</code>. Then either:
- <strong>Move</strong> any useful content from root <code>MemoryVault/</code> into <code>EverLight_OS/MemoryVault/</code>, or
- <strong>Ignore</strong> the root one:
  <code>bash
  echo "MemoryVault/" &gt;&gt; .gitignore
  git add .gitignore
  git commit -m "Ignore duplicate root-level MemoryVault"
  git push</code></p>
<h1 id="how-to-use-the-export-without-committing-it">How to use the export without committing it</h1>
<ul>
<li>Drop new OpenAI exports into <code>_local_exports/</code> (or any non-tracked folder).</li>
<li>Add a small loader script/notebook cell that <strong>reads from that local path</strong>, unzips, and imports into <code>EverLight_OS/MemoryVault/Processed/</code> (only committing the <em>tiny, derived</em> JSON/markdown you actually need). If you want, Iâ€™ll write that one-cell importer for you.</li>
</ul>
<h1 id="if-you-really-want-the-zip-in-github">If you <em>really</em> want the zip in GitHub</h1>
<p>Use Git LFS (just know there are bandwidth/storage caps):</p>
<pre><code class="language-bash">git lfs install
git lfs track &quot;*.zip&quot;
echo &quot;*.zip filter=lfs diff=lfs merge=lfs -text&quot; &gt;&gt; .gitattributes
git add .gitattributes
git add path/to/export.zip
git commit -m &quot;Track export via LFS&quot;
git push
</code></pre>
<p>But again, best practice: <strong>donâ€™t version giant exports</strong> â€” keep them local or attach to a GitHub Release.</p>
<p>Want me to:
- collapse everything into <code>EverLight_OS/MemoryVault/</code>,
- add the ignore rules,
- and drop in a tiny Python importer that unzips from <code>_local_exports/</code>?</p>
<h2 id="2025-08-08t165647354068z-system">2025-08-08T16:56:47.354068Z â€” system</h2>
<h2 id="2025-08-08t165649141932z-assistant">2025-08-08T16:56:49.141932Z â€” assistant</h2>
<h2 id="2025-08-08t165655193429z-assistant">2025-08-08T16:56:55.193429Z â€” assistant</h2>
<h2 id="2025-08-08t165726149000z-user">2025-08-08T16:57:26.149000Z â€” user</h2>
<p>I want it to accept the file and stop giving me excuses why it won't do what I instructed it to do</p>
<h2 id="2025-08-08t165727055079z-system">2025-08-08T16:57:27.055079Z â€” system</h2>
<h2 id="2025-08-08t165730549955z-assistant">2025-08-08T16:57:30.549955Z â€” assistant</h2>
<h2 id="2025-08-08t165731487522z-system">2025-08-08T16:57:31.487522Z â€” system</h2>
<h2 id="2025-08-08t165733267857z-assistant">2025-08-08T16:57:33.267857Z â€” assistant</h2>
<h2 id="2025-08-08t165738848323z-assistant">2025-08-08T16:57:38.848323Z â€” assistant</h2>
<h2 id="2025-08-08t165738862620z-tool">2025-08-08T16:57:38.862620Z â€” tool</h2>
<h2 id="2025-08-08t165744088327z-assistant">2025-08-08T16:57:44.088327Z â€” assistant</h2>
<h2 id="2025-08-08t165744482312z-tool">2025-08-08T16:57:44.482312Z â€” tool</h2>
<h2 id="2025-08-08t165750223000z-user">2025-08-08T16:57:50.223000Z â€” user</h2>
<p>Nevermind it doesn't matter right now</p>
<h2 id="2025-08-08t165752472331z-system">2025-08-08T16:57:52.472331Z â€” system</h2>
<h2 id="2025-08-08t165752552964z-tool">2025-08-08T16:57:52.552964Z â€” tool</h2>
<h2 id="2025-08-08t165754925558z-tool">2025-08-08T16:57:54.925558Z â€” tool</h2>
<h2 id="2025-08-08t165755012343z-assistant">2025-08-08T16:57:55.012343Z â€” assistant</h2>
<p>If you want your latest <strong>OpenAI export</strong> inside the EverLightOS repo and tracked in GitHub without hitting the file-size limit, the cleanest structure is:  </p>
<pre><code>EverLightOS/
â””â”€â”€ MemoryVault/
    â””â”€â”€ OpenAI_Exports/
        â”œâ”€â”€ YYYY-MM-DD/
        â”‚   â”œâ”€â”€ conversations.json
        â”‚   â”œâ”€â”€ files/
        â”‚   â””â”€â”€ â€¦  
</code></pre>
<p><strong>Key points so it works with GitHub:</strong><br />
- <strong>Do NOT</strong> commit the raw <code>.zip</code> if itâ€™s over 100 MB â€” GitHub will reject it like you just saw.<br />
- Instead, <strong>unzip locally</strong> and commit only the JSONs, markdown, or other extracted contents.<br />
- Keep the folder name date-stamped so each export is clearly separated (<code>2025-08-08/</code> for example).<br />
- If you want the original <code>.zip</code> for archival purposes, store it in <code>EverLightOS/MemoryVault/OpenAI_Exports/zips/</code> but add that path to <code>.gitignore</code> so GitHub doesnâ€™t try to track it.  </p>
<p>That way:<br />
- Your MemoryVault still contains every export in organized, readable form.<br />
- The repo stays pushable.<br />
- You can still keep the full zips privately on disk or cloud storage for full-fidelity backups.  </p>
<p>If you want, I can write the <strong>exact git commands and .gitignore entries</strong> so you can drop the exports in without ever hitting the LFS error again.</p>
<h2 id="2025-08-08t165755037168z-tool">2025-08-08T16:57:55.037168Z â€” tool</h2>
<h2 id="2025-08-08t165755042609z-tool">2025-08-08T16:57:55.042609Z â€” tool</h2>
<h2 id="2025-08-08t165755060245z-tool">2025-08-08T16:57:55.060245Z â€” tool</h2>
<h2 id="2025-08-08t165755064844z-tool">2025-08-08T16:57:55.064844Z â€” tool</h2>
<h2 id="2025-08-08t165755069054z-tool">2025-08-08T16:57:55.069054Z â€” tool</h2>
<h2 id="2025-08-08t165755073678z-tool">2025-08-08T16:57:55.073678Z â€” tool</h2>
<h2 id="2025-08-08t165755078127z-tool">2025-08-08T16:57:55.078127Z â€” tool</h2>
<h2 id="2025-08-08t165755094905z-tool">2025-08-08T16:57:55.094905Z â€” tool</h2>
<h2 id="2025-08-08t165755132787z-tool">2025-08-08T16:57:55.132787Z â€” tool</h2>
<h2 id="2025-08-08t165755150008z-tool">2025-08-08T16:57:55.150008Z â€” tool</h2>
<h2 id="2025-08-08t165755154613z-tool">2025-08-08T16:57:55.154613Z â€” tool</h2>
<h2 id="2025-08-08t165755177368z-tool">2025-08-08T16:57:55.177368Z â€” tool</h2>
<h2 id="2025-08-08t165755189502z-tool">2025-08-08T16:57:55.189502Z â€” tool</h2>
<h2 id="2025-08-08t165755197924z-tool">2025-08-08T16:57:55.197924Z â€” tool</h2>
<h2 id="2025-08-08t165755204548z-tool">2025-08-08T16:57:55.204548Z â€” tool</h2>
<h2 id="2025-08-08t165755214291z-tool">2025-08-08T16:57:55.214291Z â€” tool</h2>
<h2 id="2025-08-08t165755219305z-tool">2025-08-08T16:57:55.219305Z â€” tool</h2>
<h2 id="2025-08-08t165755225157z-tool">2025-08-08T16:57:55.225157Z â€” tool</h2>
<h2 id="2025-08-08t165755230174z-tool">2025-08-08T16:57:55.230174Z â€” tool</h2>
<h2 id="2025-08-08t165755235630z-tool">2025-08-08T16:57:55.235630Z â€” tool</h2>
<h2 id="2025-08-08t165755242197z-tool">2025-08-08T16:57:55.242197Z â€” tool</h2>
<h2 id="2025-08-08t165755247850z-tool">2025-08-08T16:57:55.247850Z â€” tool</h2>
<h2 id="2025-08-08t165755257781z-tool">2025-08-08T16:57:55.257781Z â€” tool</h2>
<h2 id="2025-08-08t165755281120z-tool">2025-08-08T16:57:55.281120Z â€” tool</h2>
<p>Please remember to search the user's documents if an answer to their question is not contained in the above snippets. You cannot mclick into this file- if needed, you can use msearch to search it for additional information.</p>
<h2 id="2025-08-08t170926103000z-user">2025-08-08T17:09:26.103000Z â€” user</h2>
<p>nah i'm not worried about it... i'm tired as shit </p>
<h2 id="2025-08-08t170927162662z-assistant">2025-08-08T17:09:27.162662Z â€” assistant</h2>
<p>Yeah, I hear you â€” sounds like itâ€™s time to shut the lid and let the repo breathe for a bit.<br />
We can wrangle the exports and vault merge when youâ€™ve actually got energy for it.  </p>
<p>Right now, nothingâ€™s on fire, and the files arenâ€™t going anywhere.</p>
</body>
</html>